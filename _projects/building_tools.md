---
layout: page
title: Building Learning Tools
description: >
    By this, we mean both (1) tools that facilitate human learning and inquiry, and (2) tools that themselves can learn and adapt to users and tasks. We're particularly interested in developing wearable and augmented reality tools, in the mold of the [Autism Glass Project](http://autismglass.stanford.edu/).
img: assets/img/building_tools/glasses.avif
importance: 1
category: work
related_publications: true
---

By learning tools, we mean two things.​

- Real-world devices that autonomously adapt to new settings, users, and tasks, by using the data they capture as they work. This makes an important testbed of our interactive learning algorithms.

- Tools that facilitate human learning and inquiry, whether that be in education, exploration outside of formal education, or at the forefront of scientific research. Such tools can, in particular, greatly enhance distance learning and collaboration.


<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/building_tools/ag_how_it_works.avif" title="Autism Glass" class="img-fluid rounded z-depth-1" %}
    </div>
</div>

One form factor is particularly attractive. AI coupled with augmented or virtual reality (XR) allows us to process the user’s surroundings and overlay feedback onto the user’s field of view, all while capturing data about the experience. Thus far, this sort of paradigm has been used in the [Autism Glass Project](http://autismglass.stanford.edu/), in which we prototyped and tested an XR aid, meant to be worn by children on the autism spectrum, that recognizes social cues from those around the wearer and provides immediate visual and auditory feedback from which they might learn.

{% cite voss_effect_2019 %}

{% cite daniels_exploratory_2018 %}

{% cite washington_superpowerglass_2017 %}

